{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA3 - Perceptron#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zhanchong Deng  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A15491777  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Perceptron as pa3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 820)\n",
      "(1000, 820)\n",
      "(819,)\n"
     ]
    }
   ],
   "source": [
    "training = pa3.loadData('pa3train.txt')\n",
    "test = pa3.loadData('pa3test.txt')\n",
    "dictionary = pa3.loadDictionary('pa3dictionary.txt')\n",
    "print(training.shape)\n",
    "print(test.shape)\n",
    "print(dictionary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Class 1 or Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subset of training data with only class 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "has1_and2 = (training[:,-1] == 1) | (training[:,-1] == 2)\n",
    "q1_training_set = training[has1_and2]\n",
    "has1_and2 = (test[:,-1] == 1) | (test[:,-1] == 2)\n",
    "q1_testing_set = test[has1_and2]\n",
    "# Sample for debugging\n",
    "sample = np.array([\n",
    "    [1,0,0,1],\n",
    "    [0,1,0,2],\n",
    "    [4,5,6,1],\n",
    "    [-1,9,-1,2]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 4 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pa3.Perceptron()\n",
    "p.fit(q1_training_set, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure errors are close to expected according to the PA (0.04, 0.07, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n",
      "0.07\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "for method in [\"single\", \"voted\", \"average\"]:\n",
    "    print(\"{0:.2f}\".format(p.error(q1_training_set, method)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Printing Training/Test Errors for 2,3,4 passes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors for 2 passes:\n",
      "\tsingle's training error is: 0.03578\n",
      "\tsingle's testing error is: 0.06101\n",
      "\tvoted's training error is: 0.03853\n",
      "\tvoted's testing error is: 0.06101\n",
      "\taverage's training error is: 0.05138\n",
      "\taverage's testing error is: 0.08223\n",
      "\n",
      "Errors for 3 passes:\n",
      "\tsingle's training error is: 0.01835\n",
      "\tsingle's testing error is: 0.04509\n",
      "\tvoted's training error is: 0.02661\n",
      "\tvoted's testing error is: 0.04244\n",
      "\taverage's training error is: 0.03486\n",
      "\taverage's testing error is: 0.06101\n",
      "\n",
      "Errors for 4 passes:\n",
      "\tsingle's training error is: 0.01651\n",
      "\tsingle's testing error is: 0.04509\n",
      "\tvoted's training error is: 0.02202\n",
      "\tvoted's testing error is: 0.04509\n",
      "\taverage's training error is: 0.03119\n",
      "\taverage's testing error is: 0.05040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    # Retrain model\n",
    "    p = pa3.Perceptron()\n",
    "    p.fit(q1_training_set, i, 1)\n",
    "    print(\"Errors for\", i, \"passes:\")\n",
    "    for method in [\"single\", \"voted\", \"average\"]:\n",
    "        print(\"\\t\" + method + \"'s training error is: \" + \"{0:.5f}\".format(p.error(q1_training_set, method)))\n",
    "        print(\"\\t\" + method + \"'s testing error is:\", \"{0:.5f}\".format(p.error(q1_testing_set, method)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Examine what w_average means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing with 3 passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pa3.Perceptron()\n",
    "p.fit(q1_training_set, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find highest 3/lowest 3 feature and their correspounding word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 most negative are: ['he ', 'team ', 'game ']\n",
      "3 most positive are: ['line ', 'program ', 'file ']\n"
     ]
    }
   ],
   "source": [
    "words_sorted = pd.Series(p.w_average, index = dictionary).sort_values().index\n",
    "print(\"3 most negative are:\", words_sorted[:3].to_list())\n",
    "print(\"3 most positive are:\", words_sorted[-3:].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs All Classfier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 6 different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for i in range(1,7):\n",
    "    model_i = pa3.Perceptron()\n",
    "    model_i.fit(training, 1, i)\n",
    "    models[i]=model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Confusion Matrix for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.DataFrame(np.zeros((7,6)), columns = [1,2,3,4,5,6], dtype = int, index = ['1','2','3','4','5','6', \"don't know\"])\n",
    "# Each data in training increments confusion matrix\n",
    "for data in test:\n",
    "    distribution = []\n",
    "    prediction = 7\n",
    "    # Predict with all classifier\n",
    "    for j in range(1,7):\n",
    "        y = models[j].predict_pass_one(data[:-1])\n",
    "        if y > 0:\n",
    "            distribution.append(y * j)\n",
    "        else:\n",
    "            distribution.append(-1)\n",
    "    # Prediction genereated\n",
    "    if np.sum(np.array(distribution) > 0) == 1:\n",
    "        prediction = (np.array(distribution)[np.array(distribution) > 0])[0]\n",
    "    else:\n",
    "        prediction = \"don't know\" # 7, index 6\n",
    "    # With actual, modify the confusion matrix\n",
    "    confusion_matrix.loc[str(prediction),data[-1]] += 1\n",
    "    \n",
    "# Now normalize the confusion matrix\n",
    "confusion_distribution = confusion_matrix / confusion_matrix.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.120370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't know</th>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1         2         3         4         5         6\n",
       "1           0.718919  0.010417  0.034286  0.021739  0.000000  0.000000\n",
       "2           0.010811  0.656250  0.034286  0.027174  0.012821  0.018519\n",
       "3           0.000000  0.015625  0.371429  0.000000  0.000000  0.027778\n",
       "4           0.016216  0.005208  0.000000  0.684783  0.000000  0.000000\n",
       "5           0.016216  0.031250  0.074286  0.005435  0.801282  0.120370\n",
       "6           0.005405  0.010417  0.034286  0.000000  0.070513  0.500000\n",
       "don't know  0.232432  0.270833  0.451429  0.260870  0.115385  0.333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Examining Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Accuracy means how many correct out of all input, thus the diagonals represent accuracies. In that case, **i will be 5**, with classifier accruacy of **80%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Accuracy means how many correct out of all input, thus the diagonals represent accuracies. In that case, **i will be 3**, with classifier accruacy of **37%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The maximum value in off-diagonal, which means mistaken predictions, happen in **i = 5, j = 6**, with error percent of **12%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't know</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1   2   3   4   5        6\n",
       "1          NaN NaN NaN NaN NaN      NaN\n",
       "2          NaN NaN NaN NaN NaN      NaN\n",
       "3          NaN NaN NaN NaN NaN      NaN\n",
       "4          NaN NaN NaN NaN NaN      NaN\n",
       "5          NaN NaN NaN NaN NaN  0.12037\n",
       "6          NaN NaN NaN NaN NaN      NaN\n",
       "don't know NaN NaN NaN NaN NaN      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_at = confusion_distribution == ((1 - np.identity(6)) * confusion_distribution.iloc[:6,:]).max().max()\n",
    "confusion_distribution[max_at]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Code from Perceptron.py:**  \n",
    "```python\n",
    "'''\n",
    "Perceptron.py\n",
    "Contains all methods for a perceptron algorithm/model.\n",
    "Author: Zhanchong Deng\n",
    "Date: 2/27/2020\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def loadData(fp):\n",
    "    newfile = open(fp, 'r')\n",
    "    newfile.seek(0)\n",
    "    raw_strings = newfile.read().split(\"\\n\")[:-1]\n",
    "    return np.array([np.array(entry.split(\" \"), dtype=\"int\") for entry in raw_strings])\n",
    "\n",
    "def loadDictionary(fp):\n",
    "    newfile = open(fp, 'r')\n",
    "    newfile.seek(0)\n",
    "    all_words = newfile.read().split(\"\\n\")\n",
    "    return np.array(all_words, dtype='str')[:-1]\n",
    "\n",
    "class Perceptron():\n",
    "    # The perceptron for:\n",
    "    w = 0         # Single\n",
    "    w_voted = []    # Voted\n",
    "    w_average = []   # Average\n",
    "    label_as_one = 0\n",
    "    \n",
    "    def fit(self, training_data, num_passes, label_as_one):\n",
    "        # Set up label mapping and initialize w\n",
    "        self.label_as_one = label_as_one\n",
    "        self.w = np.array([0] * (len(training_data[0])-1))\n",
    "        # For voted\n",
    "        cur_w_weight = 1\n",
    "        self.w_voted = []\n",
    "        self.w_average = []\n",
    "        # How many epochs\n",
    "        for cur_pass in range(num_passes):\n",
    "            for data in training_data:\n",
    "                # Transform label to 1/-1\n",
    "                y = self.transform_label(data[-1])\n",
    "                # Update case:\n",
    "                if y * np.dot(data[:-1], self.w) <= 0:\n",
    "                    self.w_voted.append([np.copy(self.w), cur_w_weight])\n",
    "                    cur_w_weight = 1\n",
    "                    self.w += y * data[:-1]\n",
    "                else:\n",
    "                    cur_w_weight += 1\n",
    "        # Record w for single, voted, as well as average\n",
    "        self.w_voted.append([np.copy(self.w), cur_w_weight])\n",
    "        self.w_average = self.set_average_w()\n",
    "            \n",
    "    \n",
    "    def transform_label(self, original_label): \n",
    "        if original_label == self.label_as_one:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    '''\n",
    "    Functions for Prediction/Testing\n",
    "    '''\n",
    "    # Calculate Error\n",
    "    def error(self, testing_data, method):\n",
    "        # Depending on what method is, calculate predictions\n",
    "        predictions = []\n",
    "        if method == \"single\":\n",
    "            predictions = self.predict_pass(testing_data)\n",
    "        elif method == \"voted\":\n",
    "            predictions = self.predict_voted(testing_data)\n",
    "        elif method == \"average\":\n",
    "            predictions = self.predict_average(testing_data)\n",
    "        # Transform test label to 1/-1\n",
    "        actual = []\n",
    "        for original_label in testing_data[:,-1]:\n",
    "            actual.append(self.transform_label(original_label))\n",
    "        return np.mean(predictions != np.array(actual))\n",
    "    \n",
    "    \n",
    "    # Single Perceptron\n",
    "    def predict_pass_one(self, a_test_data):\n",
    "        if np.dot(a_test_data, self.w) >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def predict_pass(self, testing_data):\n",
    "        return np.apply_along_axis(self.predict_pass_one, 1, testing_data[:,:-1])\n",
    "    \n",
    "    \n",
    "    # Voted Perceptron\n",
    "    def predict_voted_one(self, a_test_data):\n",
    "        output = 0\n",
    "        for pair in self.w_voted:\n",
    "            prediction = np.dot(np.array(pair[0]), a_test_data) >= 0\n",
    "            if prediction:\n",
    "                output += pair[1]\n",
    "            else:\n",
    "                output -= pair[1]\n",
    "        if output >=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def predict_voted(self, testing_data):\n",
    "        return np.apply_along_axis(self.predict_voted_one, 1, testing_data[:,:-1])\n",
    "    \n",
    "    # Average Perceptron\n",
    "    def set_average_w(self):\n",
    "        w_sum = np.array([0] * len(self.w))\n",
    "        for pair in self.w_voted:\n",
    "            w_sum += (pair[0] * pair[1])\n",
    "        return w_sum\n",
    "    \n",
    "    def predict_average_one(self, a_test_data):\n",
    "        if np.dot(a_test_data, self.w_average) >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def predict_average(self, testing_data):\n",
    "        return np.apply_along_axis(self.predict_average_one, 1, testing_data[:,:-1])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
